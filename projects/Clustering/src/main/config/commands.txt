elastic-mapreduce --create --num-instances=1 --enable-debugging --log-uri s3n://nicole.deflaux/debugLogs --name kmeans --alive

    
export JOB_FLOW_ID=

    
s3curl.pl --id personal --put target/Clustering-1.0-SNAPSHOT.jar https://s3.amazonaws.com/nicole.deflaux/emr/kmeans/Clustering-1.0-SNAPSHOT.jar -- -k

s3curl.pl --id personal --put data/cluster0.txt https://s3.amazonaws.com/nicole.deflaux/emr/kmeans/cluster0.txt -- -k

s3curl.pl --id personal --put data/tfidf.txt https://s3.amazonaws.com/nicole.deflaux/emr/kmeans/tfidf.txt -- -k

s3curl.pl --id personal --put data/dictionary.txt https://s3.amazonaws.com/nicole.deflaux/emr/kmeans/dictionary.txt -- -k

    

elastic-mapreduce --jobflow $JOB_FLOW_ID --ssh "hadoop fs -mkdir /kmeans"
elastic-mapreduce --jobflow $JOB_FLOW_ID --ssh "hadoop fs -mkdir /kmeans/initial_center"
elastic-mapreduce --jobflow $JOB_FLOW_ID --ssh "hadoop fs -cp s3n://nicole.deflaux/emr/kmeans/tfidf.txt /kmeans/tfidf.txt"
elastic-mapreduce --jobflow $JOB_FLOW_ID --ssh "hadoop fs -cp s3n://nicole.deflaux/emr/kmeans/dictionary.txt /kmeans/dictionary.txt"
elastic-mapreduce --jobflow $JOB_FLOW_ID --ssh "hadoop fs -cp s3n://nicole.deflaux/emr/kmeans/cluster0.txt /kmeans/initial_center/cluster0.txt"


elastic-mapreduce --jobflow $JOB_FLOW_ID --ssh

    
elastic-mapreduce --jobflow $JOB_FLOW_ID --json src/main/config/kmeans.json

