library('ggplot2')
library('testthat')

setwd('~/rework/competitions/loadForecasting/data')

# Quotes are from http://www.kaggle.com/c/global-energy-forecasting-competition-2012-load-forecasting/forums/t/2540/need-descriptions-of-data-files
# and http://www.kaggle.com/c/global-energy-forecasting-competition-2012-load-forecasting/data

# 'Column A is id, the identifier for each row; Column B is zone_id ranging from 1 to 21, where the 21st 'zone' represents 
# system level, which is the sum of the other 20 zones.'
# 'Please make sure the submission strictly follow the format as indicated in 'submission_template.csv', where the year was 
# sorted in smallest to largest order first, then month, then day, and then zone_id.'
st <- read.csv('submission_template.csv')
names(st)
str(st)

# 'Benchmark.csv is the forecasts from a naive multiple linear regression model I developed. It was uploaded as the entry bar 
# for this competition, as well as a sample to show the format of a submission.'
# 'Column A is id, the identifier for each row; Column B is zone_id ranging from 1 to 21, where the 21st 'zone' represents 
# system level, which is the sum of the other 20 zones.'
bm <- read.csv('Benchmark.csv')
names(bm)
str(bm)

expect_that(bm$id, equals(st$id), info="benchmark matches template")
expect_that(bm$zone_id, equals(st$zone_id))
expect_that(bm$year, equals(st$year))
expect_that(bm$month, equals(st$month))
expect_that(bm$day, equals(st$day))

# 'I believe test.csv is generated by Kaggle to test the environment. You don't need it for your forecast.'
tst <- read.csv('test.csv')
names(tst)
str(tst)

# 'Column A is zone_id ranging from 1 to 20
# Three columns of calendar variables: year, month of the year and day of the month. The last 24 columns are the 24 hours of the day.'
lh <- read.csv('Load_history.csv', na.strings = '')
names(lh)
dim(lh)
str(lh)
expect_that(is.na(subset(lh, lh$zone_id == 11 & lh$year == 2008 & lh$month == 7 & lh$day == 5)$h1), is_true())
expect_that(is.na(subset(lh, lh$zone_id == 11 & lh$year == 2005 & lh$month == 12 & lh$day == 26)$h1), is_true())
lh = na.omit(lh)

startTime=date(); startTime
iFeelLikeWaitingHours = FALSE
if(iFeelLikeWaitingHours) {
    library(reshape)
    lhLong = melt(lh, id.vars=c('zone_id','year','month','day'), variable_name='hour')
    lhts = do.call('rbind', 
                  apply(lhLong, 1, function(x) { 
        hourOfDay = as.numeric(substring(x[['hour']], 2)) - 1
        hourStr = as.character(hourOfDay)
        if(hourOfDay < 10) {
            hourStr = paste('0', hourStr, sep='')
        }
        dtString = paste(x[['year']], 
                         x[['month']], 
                         x[['day']], 
                         hourStr,
                         '00',
                         '30'
                        )
        dt = strptime(dtString, '%Y %m %d %H %M %S')
        data.frame(zone_id=x[['zone_id']],
                   timepoint=dt, 
                   load=as.numeric(sub(pattern=',', replacement='', x=x[['value']], fixed=T)))
        }
    ))
} else{
    system('python2.7 ~/rework/competitions/loadForecasting/dataTransform.py')
    lhts = read.csv('Load_history_timeseries.csv', na.strings = '', colClasses=c('numeric', 'character', 'numeric'))
    names(lhts)
    dim(lhts)
    str(lhts)
    expect_that(nrow(lhts), 
                equals(20*length(unique(lhts$timepoint))), 
                info='every time point is reported for all 20 zones')
    lhts = na.omit(lhts)
    dim(lhts)
    lhts$timepoint <- as.POSIXlt(lhts$timepoint)
    str(lhts)
}
stopTime=date(); stopTime

qplot(timepoint, load, 
      data=lhts[lhts$timepoint > as.POSIXlt('2004-05-01') & lhts$timepoint < as.POSIXlt('2004-05-10'), ], 
      color=zone_id,
      geom='line')

# 'Column A is station_id ranging from 1 to 11
# Three columns of calendar variables: year, month of the year and day of the month. The last 24 columns are the 24 hours of the day.'
th <- read.csv('temperature_history.csv', na.strings = '')
names(th)
dim(th)
str(th)
th = na.omit(th)
dim(th)

# 'Column A is id, the identifier for each row; Column B is zone_id ranging from 1 to 21, where the 21st 'zone' represents 
# system level, which is the sum of the other 20 zones.'
# 'Weights.csv shows you how we assign weights to different weeks and levels, so that you know which weeks and 
# levels are important to the final score. For instance,
## the weight of each hour of the forecasted week (7/1/2008 - 7/7/2008) at system level (sum of the 20 zones) is 160; 
## the weight of each hour of the forecasted week (7/1/2008 - 7/7/2008) at zonal level 8;
## the weight of each hour of the backcasted weeks at system level is 20;
## the weight of each hour of the backcasted weeks at zonal level is 1;'
w <- read.csv('weights.csv')
names(w)
dim(w)
str(w)
expect_that(subset(w, w$zone_id == 21 & w$year == 2008 & w$month == 7 & w$day == 5)$h1, equals(160))
expect_that(subset(w, w$zone_id == 6 & w$year == 2008 & w$month == 7 & w$day == 5)$h1, equals(8))
expect_that(subset(w, w$zone_id == 21 & w$year == 2005 & w$month == 12 & w$day == 26)$h1, equals(20))
expect_that(subset(w, w$zone_id == 6 & w$year == 2005 & w$month == 12 & w$day == 26)$h1, equals(1))

